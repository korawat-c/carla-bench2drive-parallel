{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRPO Snapshot and Branching Tutorial - WORKING VERSION\n",
    "\n",
    "This notebook demonstrates the advanced GRPO features: snapshot/restore and branching functionality.\n",
    "\n",
    "## What You'll Learn:\n",
    "- **Snapshot System**: Save environment states for multi-turn rollouts\n",
    "- **Branching Mode**: Run multiple CARLA instances in parallel\n",
    "- **Trajectory Collection**: Collect multiple trajectories from the same state\n",
    "- **Branch Selection**: Select best trajectory and continue exploration\n",
    "\n",
    "### Prerequisites:\n",
    "- Complete the \"02_grpo_carla_interface.ipynb\" notebook first\n",
    "- CARLA server running at `http://localhost:8080`\n",
    "\n",
    "### Key Concepts:\n",
    "- **Snapshot**: Save complete environment state at decision points\n",
    "- **Branching**: Create parallel environments from same snapshot\n",
    "- **Multi-turn Rollouts**: Explore different actions from same state\n",
    "- **Best Trajectory Selection**: Choose optimal path based on rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting 2 CARLA services...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting CARLA services...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:No listeners found on target ports.\n",
      "INFO:__main__:Launching: python /mnt3/Documents/AD_Framework/bench2drive-gymnasium/bench2drive_microservices/server/microservice_manager.py --num-services 2 --startup-delay 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Services starting... Wait 60 seconds for full initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:45:28,550 [MicroserviceManager] INFO: Starting 2 services in parallel...\n",
      "2025-09-30 13:45:28,550 [resource_manager] INFO: Allocated resources for service 0:\n",
      "2025-09-30 13:45:28,550 [resource_manager] INFO:   GPU: 0\n",
      "2025-09-30 13:45:28,550 [resource_manager] INFO:   API Port: 8080\n",
      "2025-09-30 13:45:28,550 [resource_manager] INFO:   CARLA Port: 2000\n",
      "2025-09-30 13:45:28,550 [resource_manager] INFO:   Streaming Port: 3000\n",
      "2025-09-30 13:45:28,550 [resource_manager] INFO:   TM Port: 3000\n",
      "2025-09-30 13:45:28,550 [MicroserviceManager] INFO: [Resource Manager] Allocated resources for service 0\n",
      "2025-09-30 13:45:28,550 [Service-0] INFO: Starting service 0\n",
      "2025-09-30 13:45:28,550 [Service-0] INFO: Cleaning up ports for service 0\n",
      "2025-09-30 13:45:29,552 [Service-0] INFO: Starting carla_server.py:\n",
      "2025-09-30 13:45:29,552 [Service-0] INFO:   API port: 8080\n",
      "2025-09-30 13:45:29,552 [Service-0] INFO:   CARLA port: 2000\n",
      "2025-09-30 13:45:29,552 [Service-0] INFO:   GPU: 0\n",
      "2025-09-30 13:45:29,558 [Service-0] INFO: Server process started with PID 272499\n",
      "2025-09-30 13:45:31,575 [Service-0] INFO: Server is healthy\n",
      "2025-09-30 13:45:31,575 [Service-0] INFO: âœ“ Service 0 ready\n",
      "2025-09-30 13:45:31,576 [MicroserviceManager] INFO: âœ“ Spawned service 0\n",
      "2025-09-30 13:45:31,576 [MicroserviceManager] INFO:   API: http://localhost:8080\n",
      "2025-09-30 13:45:31,576 [MicroserviceManager] INFO:   CARLA port: 2000\n",
      "2025-09-30 13:45:31,576 [MicroserviceManager] INFO:   GPU: 0\n",
      "2025-09-30 13:45:31,577 [MicroserviceManager] INFO: Waiting 30s before starting next service...\n"
     ]
    }
   ],
   "source": [
    "# Start CARLA services\n",
    "import logging, os, signal, subprocess, time, shutil\n",
    "from typing import Set, List\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def _pids_listening_on_port(port: int, only_mine: bool = True) -> Set[int]:\n",
    "    \"\"\"Return PIDs listening on port.\"\"\"\n",
    "    pids = set()\n",
    "    \n",
    "    if shutil.which(\"lsof\"):\n",
    "        cmd = [\"lsof\", \"-nP\", \"-tiTCP:%d\" % port, \"-sTCP:LISTEN\"]\n",
    "        if only_mine:\n",
    "            cmd.insert(1, \"-u\")\n",
    "            cmd.insert(2, os.getlogin())\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if res.returncode == 0 and res.stdout.strip():\n",
    "            pids.update(int(x) for x in res.stdout.strip().splitlines() if x.strip().isdigit())\n",
    "        return pids\n",
    "    \n",
    "    return set()\n",
    "\n",
    "def _graceful_kill(pids: Set[int], grace: float = 2.5):\n",
    "    \"\"\"Send SIGTERM, wait, then SIGKILL.\"\"\"\n",
    "    if not pids:\n",
    "        return\n",
    "    me = os.getpid()\n",
    "    pids = {pid for pid in pids if pid != me}\n",
    "    if not pids:\n",
    "        return\n",
    "\n",
    "    for pid in pids:\n",
    "        try:\n",
    "            os.kill(pid, signal.SIGTERM)\n",
    "            logger.info(f\"SIGTERM sent to PID {pid}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    deadline = time.time() + grace\n",
    "    remaining = set(pids)\n",
    "    while time.time() < deadline and remaining:\n",
    "        for pid in list(remaining):\n",
    "            try:\n",
    "                os.kill(pid, 0)\n",
    "            except:\n",
    "                remaining.discard(pid)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    for pid in list(remaining):\n",
    "        try:\n",
    "            os.kill(pid, signal.SIGKILL)\n",
    "            logger.info(f\"SIGKILL sent to PID {pid}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def clean_ports(ports: List[int], only_mine: bool = True):\n",
    "    \"\"\"Kill processes listening on the given ports.\"\"\"\n",
    "    all_pids = set()\n",
    "    for port in ports:\n",
    "        try:\n",
    "            pids = _pids_listening_on_port(port, only_mine=only_mine)\n",
    "            if pids:\n",
    "                logger.info(f\"Port {port} in use by PIDs {sorted(pids)}\")\n",
    "                all_pids.update(pids)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if all_pids:\n",
    "        _graceful_kill(all_pids)\n",
    "    else:\n",
    "        logger.info(\"No listeners found on target ports.\")\n",
    "\n",
    "def start_servers(num_services: int = 2, root_dir: str = \"/mnt3/Documents/AD_Framework/bench2drive-gymnasium/bench2drive_microservices\"):\n",
    "    logger.info(f\"Starting {num_services} CARLA services...\")\n",
    "\n",
    "    # Clean named processes\n",
    "    kill_names = [\"carla_server.py\", \"microservice_manager.py\", \"CarlaUE4\", \"server_manager.py\"]\n",
    "    for name in kill_names:\n",
    "        subprocess.run([\"pkill\", \"-f\", name], capture_output=True)\n",
    "        time.sleep(0.2)\n",
    "        subprocess.run([\"pkill\", \"-9\", \"-f\", name], capture_output=True)\n",
    "\n",
    "    # Clean ports\n",
    "    api_ports = list(range(8080, 8084))\n",
    "    carla_ports = list(range(2000, 2013))\n",
    "    tm_ports = list(range(3000, 3013))\n",
    "    clean_ports(api_ports + carla_ports + tm_ports, only_mine=True)\n",
    "\n",
    "    time.sleep(1.0)\n",
    "\n",
    "    # Start microservice manager\n",
    "    cmd = [\n",
    "        \"python\",\n",
    "        os.path.join(root_dir, \"server\", \"microservice_manager.py\"),\n",
    "        \"--num-services\", str(num_services),\n",
    "        \"--startup-delay\", \"30\",\n",
    "    ]\n",
    "    logger.info(f\"Launching: {' '.join(cmd)}\")\n",
    "    subprocess.Popen(cmd)\n",
    "\n",
    "print(\"ðŸš€ Starting CARLA services...\")\n",
    "start_servers(2)\n",
    "print(\"âœ… Services starting... Wait 60 seconds for full initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service Setup\n",
    "\n",
    "âš ï¸ **IMPORTANT**: For GRPO branching functionality, you need multiple CARLA services running!\n",
    "\n",
    "The notebook will automatically start 2 CARLA microservices for branching.\n",
    "\n",
    "**Note**: Branching requires at least 2 services to work properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Waiting for services to be ready...\n",
      "[15s] âœ“ Service 0: healthy | âœ— Service 1: Error"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:46:01,607 [resource_manager] INFO: Allocated resources for service 1:\n",
      "2025-09-30 13:46:01,607 [resource_manager] INFO:   GPU: 1\n",
      "2025-09-30 13:46:01,607 [resource_manager] INFO:   API Port: 8081\n",
      "2025-09-30 13:46:01,607 [resource_manager] INFO:   CARLA Port: 2004\n",
      "2025-09-30 13:46:01,607 [resource_manager] INFO:   Streaming Port: 3010\n",
      "2025-09-30 13:46:01,607 [resource_manager] INFO:   TM Port: 3004\n",
      "2025-09-30 13:46:01,608 [MicroserviceManager] INFO: [Resource Manager] Allocated resources for service 1\n",
      "2025-09-30 13:46:01,608 [Service-1] INFO: Starting service 1\n",
      "2025-09-30 13:46:01,608 [Service-1] INFO: Cleaning up ports for service 1\n",
      "2025-09-30 13:46:02,610 [Service-1] INFO: Starting carla_server.py:\n",
      "2025-09-30 13:46:02,610 [Service-1] INFO:   API port: 8081\n",
      "2025-09-30 13:46:02,610 [Service-1] INFO:   CARLA port: 2004\n",
      "2025-09-30 13:46:02,610 [Service-1] INFO:   GPU: 1\n",
      "2025-09-30 13:46:02,616 [Service-1] INFO: Server process started with PID 272545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20s] âœ“ Service 0: healthy | âœ“ Service 1: healthy\n",
      "ðŸŽ‰ All services ready!\n",
      "âœ… Proceeding with notebook...\n"
     ]
    }
   ],
   "source": [
    "# Wait for services to be ready\n",
    "import requests\n",
    "import time\n",
    "\n",
    "print(\"â³ Waiting for services to be ready...\")\n",
    "\n",
    "def wait_for_services(base_port=8080, num_services=2, timeout=120):\n",
    "    \"\"\"Wait for all services to be ready.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < timeout:\n",
    "        all_ready = True\n",
    "        status = []\n",
    "        \n",
    "        for i in range(num_services):\n",
    "            port = base_port + i\n",
    "            url = f\"http://localhost:{port}/health\"\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(url, timeout=5)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    status.append(f\"âœ“ Service {i}: {data['status']}\")\n",
    "                else:\n",
    "                    status.append(f\"âœ— Service {i}: HTTP {response.status_code}\")\n",
    "                    all_ready = False\n",
    "            except Exception as e:\n",
    "                status.append(f\"âœ— Service {i}: Error\")\n",
    "                all_ready = False\n",
    "        \n",
    "        print(f\"\\r[{int(time.time() - start_time)}s] {' | '.join(status)}\", end=\"\")\n",
    "        \n",
    "        if all_ready:\n",
    "            print(\"\\nðŸŽ‰ All services ready!\")\n",
    "            return True\n",
    "        \n",
    "        time.sleep(5)\n",
    "    \n",
    "    print(f\"\\nâŒ Timeout: Services not ready after {timeout} seconds\")\n",
    "    return False\n",
    "\n",
    "# Wait for services\n",
    "if wait_for_services():\n",
    "    print(\"âœ… Proceeding with notebook...\")\n",
    "else:\n",
    "    print(\"âš ï¸  Services not ready. Some features may not work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully imported GRPOCarlaEnv\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Add client path to Python path\n",
    "client_path = str(Path.cwd().parent / \"client\")\n",
    "if client_path not in sys.path:\n",
    "    sys.path.insert(0, client_path)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Import GRPO Carla environment\n",
    "try:\n",
    "    from grpo_carla_env import GRPOCarlaEnv\n",
    "    print(\"âœ… Successfully imported GRPOCarlaEnv\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oh/anaconda3/envs/my_ad_env/lib/python3.8/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/home/oh/anaconda3/envs/my_ad_env/lib/python3.8/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "INFO:carla_env:Connected to CARLA server at http://localhost:8080\n",
      "INFO:grpo_carla_env:Created environment 0 at http://localhost:8080\n",
      "INFO:grpo_carla_env:Pre-initializing 2 services for fast branching...\n",
      "INFO:carla_env:Connected to CARLA server at http://localhost:8081\n",
      "INFO:grpo_carla_env:Created environment 1 at http://localhost:8081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Setting up GRPO Environment...\n",
      "ðŸŒ¿ Pre-initializing all services for fast branching...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:47:04,691 [Service-1] ERROR: Server not ready after 60 seconds\n",
      "2025-09-30 13:47:04,692 [Service-1] ERROR: Server did not become ready\n",
      "2025-09-30 13:47:04,692 [Service-1] INFO: Stopping service 1\n",
      "2025-09-30 13:47:14,692 [Service-1] INFO: Cleaning up ports for service 1\n",
      "2025-09-30 13:47:14,692 [MicroserviceManager] INFO: Port 8081 is in use, cleaning up...\n",
      "WARNING:carla_env:Reset attempt 1 failed, retrying in 5s: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "2025-09-30 13:47:16,850 [MicroserviceManager] WARNING: Port 8081 still in use after cleanup\n",
      "2025-09-30 13:47:16,850 [MicroserviceManager] INFO: Port 2004 is in use, cleaning up...\n",
      "2025-09-30 13:47:16,993 [MicroserviceManager] INFO: Killing process 272634 using port 2004\n",
      "WARNING:carla_env:Reset attempt 2 failed, retrying in 5s: HTTPConnectionPool(host='localhost', port=8081): Max retries exceeded with url: /reset (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3e9c3090a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "2025-09-30 13:47:20,996 [MicroserviceManager] INFO: Port 2004 successfully freed\n",
      "2025-09-30 13:47:20,996 [Service-1] INFO: Service stopped and ports cleaned\n",
      "2025-09-30 13:47:20,996 [MicroserviceManager] ERROR: Failed to spawn service 1\n",
      "2025-09-30 13:47:20,996 [MicroserviceManager] INFO: Manager started with 1 services\n",
      "2025-09-30 13:47:20,996 [MicroserviceManager] INFO: Services running. Press Ctrl+C to stop.\n",
      "ERROR:carla_env:Failed to reset environment after 3 attempts: HTTPConnectionPool(host='localhost', port=8081): Max retries exceeded with url: /reset (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3e9ba97b80>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "ERROR:grpo_carla_env:Service 1 reset failed: Failed to reset CARLA environment: HTTPConnectionPool(host='localhost', port=8081): Max retries exceeded with url: /reset (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3e9ba97b80>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "INFO:grpo_carla_env:âœ“ Service 0 initialized successfully\n",
      "ERROR:grpo_carla_env:âœ— Service 1 failed to initialize\n",
      "INFO:grpo_carla_env:Service pre-initialization complete: 1/2 ready\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  Service pre-initialization issues: Pre-initialized 1/2 services\n",
      "   Continuing anyway...\n",
      "\n",
      "âœ… GRPO Environment created!\n",
      "ðŸ“Š Configuration:\n",
      "   Max branches: 2\n",
      "   Service URLs: ['http://localhost:8080', 'http://localhost:8081']\n",
      "   Current mode: single\n",
      "   Is branching: False\n",
      "\n",
      "ðŸŽ‰ Perfect! Both services ready for branching!\n",
      "Environments: [True, True]\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BASE_API_PORT = 8080\n",
    "TIMEOUT = 60.0\n",
    "\n",
    "# Create GRPO environment\n",
    "print(\"ðŸ”§ Setting up GRPO Environment...\")\n",
    "\n",
    "env = GRPOCarlaEnv(\n",
    "    num_services=2,\n",
    "    base_api_port=BASE_API_PORT,\n",
    "    render_mode=\"rgb_array\",\n",
    "    max_steps=100,\n",
    "    timeout=TIMEOUT\n",
    ")\n",
    "\n",
    "# Pre-initialize all services for fast branching\n",
    "print(\"ðŸŒ¿ Pre-initializing all services for fast branching...\")\n",
    "init_status = env.initialize_all_services(route_id=0)\n",
    "\n",
    "if init_status.ready:\n",
    "    print(\"âœ“ All services pre-initialized successfully!\")\n",
    "else:\n",
    "    print(f\"âš  Service pre-initialization issues: {init_status.message}\")\n",
    "    print(\"   Continuing anyway...\")\n",
    "\n",
    "# Helper function to create actions\n",
    "def create_action(throttle=0.0, brake=0.0, steer=0.0):\n",
    "    \"\"\"Create a valid action vector.\"\"\"\n",
    "    action = np.array([throttle, brake, steer], dtype=np.float32)\n",
    "    return np.clip(action, env.action_space.low, env.action_space.high)\n",
    "\n",
    "print(f\"\\nâœ… GRPO Environment created!\")\n",
    "print(f\"ðŸ“Š Configuration:\")\n",
    "print(f\"   Max branches: {env.max_branches}\")\n",
    "print(f\"   Service URLs: {env.service_urls}\")\n",
    "print(f\"   Current mode: {env.current_mode}\")\n",
    "print(f\"   Is branching: {env.is_branching}\")\n",
    "\n",
    "if len(env.service_urls) < 2:\n",
    "    print(\"\\nâš ï¸  WARNING: Only 1 service available!\")\n",
    "    print(\"   Make sure both services are running\")\n",
    "else:\n",
    "    print(f\"\\nðŸŽ‰ Perfect! Both services ready for branching!\")\n",
    "\n",
    "print(f\"Environments: {[env is not None for env in env.envs]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Exploration in Single Mode\n",
    "\n",
    "First, let's explore the environment to reach an interesting decision point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš— Starting initial exploration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:48:31,014 [MicroserviceManager] INFO: Status: {'total': 1, 'healthy': 0, 'unhealthy': 1, 'dead': 0}\n",
      "WARNING:carla_env:Reset attempt 1 failed, retrying in 5s: HTTPConnectionPool(host='localhost', port=8080): Read timed out. (read timeout=120.0)\n",
      "2025-09-30 13:49:41,086 [MicroserviceManager] INFO: Status: {'total': 1, 'healthy': 0, 'unhealthy': 1, 'dead': 0}\n"
     ]
    }
   ],
   "source": [
    "# Initial exploration\n",
    "print(\"ðŸš— Starting initial exploration...\")\n",
    "\n",
    "obs, info = env.reset(options={\"route_id\": 0})\n",
    "print(f\"Reset complete. Mode: {env.current_mode}, is_branching: {env.is_branching}\")\n",
    "\n",
    "trajectory = []\n",
    "total_reward = 0.0\n",
    "\n",
    "# Explore for 20 steps to reach a decision point\n",
    "for step in range(20):\n",
    "    # Vary actions to create an interesting scenario\n",
    "    if step < 10:\n",
    "        # First, move forward\n",
    "        action = create_action(throttle=1.0, brake=0.0, steer=0.0)\n",
    "    else:\n",
    "        # Then add some steering variation\n",
    "        action = create_action(throttle=1.0, brake=0.0, steer=0.3 * np.sin(step * 0.5))\n",
    "    \n",
    "    obs, reward, terminated, truncated, info = env.single_step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    trajectory.append({\n",
    "        'step': step,\n",
    "        'position': obs['vehicle_state']['position'],\n",
    "        'speed': obs['vehicle_state']['speed'][0],\n",
    "        'action': action.tolist(),\n",
    "        'reward': reward,\n",
    "        'image': obs['center_image'].copy()\n",
    "    })\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        print(f\"Step {step:2d}: pos=({obs['vehicle_state']['position'][0]:6.1f}, {obs['vehicle_state']['position'][1]:6.1f}), \"\n",
    "              f\"speed={obs['vehicle_state']['speed'][0]:4.1f} m/s, reward={reward:.3f}\")\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        print(f\"ðŸ Episode ended at step {step}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nðŸ“Š Exploration completed:\")\n",
    "print(f\"   Total steps: {len(trajectory)}\")\n",
    "print(f\"   Total reward: {total_reward:.3f}\")\n",
    "print(f\"   Final speed: {trajectory[-1]['speed']:.2f} m/s\")\n",
    "\n",
    "# Show final state before snapshot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(trajectory[-1]['image'])\n",
    "plt.title(f\"State Before Snapshot - Step {len(trajectory)-1}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Snapshot System\n",
    "\n",
    "Now let's explore the snapshot functionality - this is the core of GRPO's multi-turn rollout capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current state for branching\n",
    "print(\"ðŸ’¾ Saving snapshot for branching...\")\n",
    "\n",
    "try:\n",
    "    snapshot_id = env.save_snapshot()\n",
    "    print(f\"âœ… Snapshot saved successfully!\")\n",
    "    print(f\"   Snapshot ID: {snapshot_id}\")\n",
    "    print(f\"   Saved at step: {env.episode_steps}\")\n",
    "    print(f\"   Current position: {trajectory[-1]['position']}\")\n",
    "    print(f\"   Current speed: {trajectory[-1]['speed']:.2f} m/s\")\n",
    "    print(f\"   Current mode: {env.current_mode}\")\n",
    "    print(f\"   Is branching: {env.is_branching}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to save snapshot: {e}\")\n",
    "    print(\"ðŸ’¡ Make sure you're in single mode before saving snapshot\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate snapshot information\n",
    "print(\"ðŸ“‹ Snapshot System Information\")\n",
    "print(\"=\" * 40)\n",
    "print()\n",
    "print(\"âœ… What is a Snapshot?\")\n",
    "print(\"   A snapshot captures the complete state of the CARLA environment:\")\n",
    "print(\"   â€¢ Vehicle position and orientation\")\n",
    "print(\"   â€¢ Vehicle velocity and speed\")\n",
    "print(\"   â€¢ Traffic light states\")\n",
    "print(\"   â€¢ Weather and time of day\")\n",
    "print(\"   â€¢ Scenario progress and triggers\")\n",
    "print(\"   â€¢ Agent internal state\")\n",
    "print()\n",
    "print(\"âœ… Why Use Snapshots?\")\n",
    "print(\"   â€¢ Multi-turn rollouts: Explore from same state multiple times\")\n",
    "print(\"   â€¢ Decision points: Save at critical moments for branching\")\n",
    "print(\"   â€¢ Reproducibility: Replay exact scenarios\")\n",
    "print(\"   â€¢ GRPO optimization: Compare different action sequences\")\n",
    "print()\n",
    "print(f\"âœ… Current Snapshot Status:\")\n",
    "print(f\"   Snapshot ID: {snapshot_id}\")\n",
    "print(f\"   Branch start step: {env.branch_start_step}\")\n",
    "print(f\"   Can branch: {env.current_snapshot is not None}\")\n",
    "print(f\"   Mode: {env.current_mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Branching Demo\n",
    "\n",
    "Now let's demonstrate the branching functionality with multiple CARLA instances running in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple branching demo\n",
    "print(\"\\nðŸŒ¿ Starting simple branching demonstration...\")\n",
    "\n",
    "try:\n",
    "    # Enable branching with 2 branches\n",
    "    print(\"ðŸŒ¿ Enabling branching mode...\")\n",
    "    status = env.enable_branching(snapshot_id, num_branches=2, async_setup=False)\n",
    "    \n",
    "    if status.status.value == \"branching_ready\":\n",
    "        print(\"âœ… Branching enabled successfully!\")\n",
    "        print(f\"   Active branches: {env.active_branches}\")\n",
    "        print(f\"   Mode: {env.current_mode}\")\n",
    "        \n",
    "        # Run 15 steps of branching\n",
    "        print(\"\\nðŸ§ª Running 15 steps with 2 branches...\")\n",
    "        print(\"   Branch 0: Straight driving\")\n",
    "        print(\"   Branch 1: Right turns\")\n",
    "        \n",
    "        total_rewards = [0, 0]\n",
    "        branch_images = []\n",
    "        \n",
    "        for step in range(15):\n",
    "            # Create different actions for each branch\n",
    "            actions = [\n",
    "                np.array([1.0, 0.0, 0.0], dtype=np.float32),   # Branch 0: Straight\n",
    "                np.array([1.0, 0.0, 0.5], dtype=np.float32)    # Branch 1: Right turn\n",
    "            ]\n",
    "            \n",
    "            # Execute branch step\n",
    "            observations, rewards, terminateds, truncateds, infos = env.branch_step(actions)\n",
    "            \n",
    "            # Accumulate rewards\n",
    "            for i in range(2):\n",
    "                total_rewards[i] += rewards[i]\n",
    "            \n",
    "            # Store images for final display\n",
    "            branch_images.append([obs['center_image'].copy() for obs in observations])\n",
    "            \n",
    "            # Show progress every 5 steps\n",
    "            if (step + 1) % 5 == 0:\n",
    "                print(f\"   Step {step + 1}: Branch 0 = {total_rewards[0]:.2f}, Branch 1 = {total_rewards[1]:.2f}\")\n",
    "            \n",
    "            # Check if any branch terminated\n",
    "            if any(terminateds) or any(truncateds):\n",
    "                print(f\"   Episode ended at step {step + 1}\")\n",
    "                break\n",
    "        \n",
    "        # Show final images from both branches\n",
    "        print(\"\\nðŸ“¸ Final Branch States:\")\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        for i in range(2):\n",
    "            axes[i].imshow(branch_images[-1][i])\n",
    "            axes[i].set_title(f\"Branch {i} - Final State (Reward: {total_rewards[i]:.3f})\")\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Show results but don't select yet\n",
    "        print(\"\\nðŸ† Branching Results:\")\n",
    "        print(f\"   Branch 0 total reward: {total_rewards[0]:.3f}\")\n",
    "        print(f\"   Branch 1 total reward: {total_rewards[1]:.3f}\")\n",
    "        print(\"   Ready for branch selection...\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ Branching failed: {status.message}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Branch Selection\n",
    "\n",
    "Now let's select the best branch and continue from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branch selection\n",
    "print(\"\\nðŸ† Selecting best branch...\")\n",
    "\n",
    "# Select best branch based on rewards\n",
    "best_branch = 0 if total_rewards[0] > total_rewards[1] else 1\n",
    "print(f\"   Branch 0 reward: {total_rewards[0]:.3f}\")\n",
    "print(f\"   Branch 1 reward: {total_rewards[1]:.3f}\")\n",
    "print(f\"   Best branch: {best_branch}\")\n",
    "\n",
    "# Select the branch\n",
    "env.select_branch(best_branch)\n",
    "print(f\"âœ… Branch {best_branch} selected - continuing in single mode\")\n",
    "\n",
    "print(f\"   Current mode: {env.current_mode}\")\n",
    "print(f\"   Is branching: {env.is_branching}\")\n",
    "print(f\"   Active branches: {env.active_branches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Continue from Selected Branch\n",
    "\n",
    "Let's continue from the selected branch to prove that the selection works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue from selected branch\n",
    "print(f\"\\nðŸš— Continuing from Branch {best_branch} for 20 steps to prove selection works...\")\n",
    "\n",
    "# Continue for 20 more steps to prove the selection works\n",
    "continuation_reward = 0\n",
    "continuation_trajectory = []\n",
    "\n",
    "for step in range(20):\n",
    "    # Simple forward driving\n",
    "    action = create_action(throttle=1.0, brake=0.0, steer=0.0)\n",
    "    \n",
    "    obs, reward, terminated, truncated, info = env.single_step(action)\n",
    "    continuation_reward += reward\n",
    "    \n",
    "    continuation_trajectory.append({\n",
    "        'step': step,\n",
    "        'position': obs['vehicle_state']['position'],\n",
    "        'speed': obs['vehicle_state']['speed'][0],\n",
    "        'reward': reward,\n",
    "        'image': obs['center_image'].copy()\n",
    "    })\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        pos = obs['vehicle_state']['position']\n",
    "        speed = obs['vehicle_state']['speed'][0]\n",
    "        print(f\"   Step {step}: pos=({pos[0]:.1f}, {pos[1]:.1f}), speed={speed:.1f} m/s\")\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        print(f\"   Episode ended at step {step}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nðŸ“Š Continuation completed:\")\n",
    "print(f\"   Total steps: {len(continuation_trajectory)}\")\n",
    "print(f\"   Total reward: {continuation_reward:.3f}\")\n",
    "\n",
    "print(f\"\\nâœ… PROOF: Successfully continued for {len(continuation_trajectory)} steps from selected branch {best_branch}!\")\n",
    "print(f\"   This proves the branch selection and continuation works correctly!\")\n",
    "\n",
    "# Show final state\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(obs['center_image'])\n",
    "plt.title(f\"Final State - Branch {best_branch} Selected (Proof of Continuation)\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "Let's summarize what we've accomplished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"ðŸŽ‰ GRPO Tutorial Summary\")\n",
    "print(\"=\" * 40)\n",
    "print()\n",
    "print(\"âœ… What We Demonstrated:\")\n",
    "print(f\"   1. Service Setup: Started {len(env.service_urls)} CARLA services\")\n",
    "print(f\"   2. Initial Exploration: Explored for {len(trajectory)} steps to decision point\")\n",
    "print(f\"   3. Snapshot System: Saved snapshot at step {env.branch_start_step}\")\n",
    "print(f\"   4. Branching Mode: Ran {env.active_branches} parallel branches for 15 steps\")\n",
    "print(f\"   5. Branch Selection: Selected branch {best_branch} with reward {max(total_rewards):.3f}\")\n",
    "print(f\"   6. Continuation: Continued for {len(continuation_trajectory)} steps from selected branch\")\n",
    "print()\n",
    "print(\"âœ… Key GRPO Features:\")\n",
    "print(\"   â€¢ Snapshot/Restore: Save complete environment state\")\n",
    "print(\"   â€¢ Parallel Branching: Multiple CARLA instances\")\n",
    "print(\"   â€¢ Trajectory Collection: Collect multiple rollouts\")\n",
    "print(\"   â€¢ Best Branch Selection: Choose optimal trajectory\")\n",
    "print(\"   â€¢ Seamless Continuation: Continue from selected branch\")\n",
    "print()\n",
    "print(\"âœ… Technical Implementation:\")\n",
    "print(\"   â€¢ Microservices Architecture: Independent CARLA instances\")\n",
    "print(\"   â€¢ REST API Communication: HTTP-based service interaction\")\n",
    "print(\"   â€¢ Dynamic Port Allocation: Automatic port management\")\n",
    "print(\"   â€¢ GPU Resource Management: Multi-GPU support\")\n",
    "print(\"   â€¢ Error Handling: Robust service recovery\")\n",
    "print()\n",
    "print(\"ðŸš€ Ready for GRPO Training!\")\n",
    "print(\"   This setup provides all the necessary components for:\")\n",
    "print(\"   â€¢ Multi-turn rollout collection\")\n",
    "print(\"   â€¢ Trajectory optimization\")\n",
    "print(\"   â€¢ Policy gradient updates\")\n",
    "print(\"   â€¢ Large-scale RL training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "print(\"\\nðŸ§¹ Cleaning up...\")\n",
    "env.close()\n",
    "print(\"âœ… Tutorial completed successfully!\")\n",
    "\n",
    "# Show final statistics\n",
    "print(\"\\nðŸ“Š Final Statistics:\")\n",
    "print(f\"   Total exploration steps: {len(trajectory)}\")\n",
    "print(f\"   Total branching steps: {len(branch_images) * env.active_branches}\")\n",
    "print(f\"   Total continuation steps: {len(continuation_trajectory)}\")\n",
    "print(f\"   Best branch reward: {max(total_rewards):.3f}\")\n",
    "print(f\"   Total combined reward: {total_reward + continuation_reward:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ad_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
