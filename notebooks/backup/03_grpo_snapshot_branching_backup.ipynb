{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRPO Snapshot and Branching Tutorial\n",
    "\n",
    "This notebook demonstrates the advanced GRPO features: snapshot/restore and branching functionality.\n",
    "\n",
    "## What You'll Learn:\n",
    "- **Snapshot System**: Save environment states for multi-turn rollouts\n",
    "- **Branching Mode**: Run multiple CARLA instances in parallel\n",
    "- **Trajectory Collection**: Collect multiple trajectories from the same state\n",
    "- **Branch Selection**: Select best trajectory and continue exploration\n",
    "\n",
    "### Prerequisites:\n",
    "- Complete the \"02_grpo_carla_interface.ipynb\" notebook first\n",
    "- CARLA server running at `http://localhost:8080`\n",
    "\n",
    "### Key Concepts:\n",
    "- **Snapshot**: Save complete environment state at decision points\n",
    "- **Branching**: Create parallel environments from same snapshot\n",
    "- **Multi-turn Rollouts**: Explore different actions from same state\n",
    "- **Best Trajectory Selection**: Choose optimal path based on rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Killing CarlaUE4 process with PID 269915 on GPU 0\n",
      "No python processes found on GPU 0\n",
      "No CarlaUE4 processes found on GPU 1\n",
      "No python processes found on GPU 1\n"
     ]
    }
   ],
   "source": [
    "import subprocess, re\n",
    "\n",
    "def kill_carla_processes_on_gpu(gpu_index: int = 0):\n",
    "    \"\"\"Kill CARLA processes on specific GPU\"\"\"\n",
    "    try:\n",
    "        raw = subprocess.check_output(\"nvidia-smi\", shell=True).decode()\n",
    "        pattern = rf'\\|\\s+{gpu_index}\\s+\\S+\\s+\\S+\\s+(\\d+)\\s+C\\+G\\s+.*CarlaUE4'\n",
    "        pids = re.findall(pattern, raw)\n",
    "        if not pids:\n",
    "            print(f\"No CarlaUE4 processes found on GPU {gpu_index}\")\n",
    "            return\n",
    "        for pid in pids:\n",
    "            print(f\"Killing CarlaUE4 process with PID {pid} on GPU {gpu_index}\")\n",
    "            subprocess.run([\"kill\", \"-9\", pid], check=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error killing CARLA processes: {e}\")\n",
    "\n",
    "def kill_python_processes_on_gpu(gpu_index: int = 0):\n",
    "    \"\"\"Kill Python processes on specific GPU\"\"\"\n",
    "    try:\n",
    "        raw = subprocess.check_output(\"nvidia-smi\", shell=True).decode()\n",
    "        pattern = rf'\\|\\s+{gpu_index}\\s+\\S+\\s+\\S+\\s+(\\d+)\\s+C\\s+.*bin/python'\n",
    "        pids = re.findall(pattern, raw)\n",
    "        if not pids:\n",
    "            print(f\"No python processes found on GPU {gpu_index}\")\n",
    "            return\n",
    "        for pid in pids:\n",
    "            print(f\"Killing python process with PID {pid} on GPU {gpu_index}\")\n",
    "            subprocess.run([\"kill\", \"-9\", pid], check=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error killing Python processes: {e}\")\n",
    "\n",
    "def cleanup_gpu_processes():\n",
    "    \"\"\"Clean up GPU processes\"\"\"\n",
    "    for gpu_id in [0, 1]:\n",
    "        kill_carla_processes_on_gpu(gpu_id)\n",
    "        kill_python_processes_on_gpu(gpu_id)\n",
    "\n",
    "cleanup_gpu_processes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:41:31,077 [MicroserviceManager] INFO: Starting 2 services in parallel...\n",
      "2025-09-30 13:41:31,077 [resource_manager] INFO: Allocated resources for service 0:\n",
      "2025-09-30 13:41:31,078 [resource_manager] INFO:   GPU: 0\n",
      "2025-09-30 13:41:31,078 [resource_manager] INFO:   API Port: 8080\n",
      "2025-09-30 13:41:31,078 [resource_manager] INFO:   CARLA Port: 2000\n",
      "2025-09-30 13:41:31,078 [resource_manager] INFO:   Streaming Port: 3000\n",
      "2025-09-30 13:41:31,078 [resource_manager] INFO:   TM Port: 3000\n",
      "2025-09-30 13:41:31,078 [MicroserviceManager] INFO: [Resource Manager] Allocated resources for service 0\n",
      "2025-09-30 13:41:31,078 [Service-0] INFO: Starting service 0\n",
      "2025-09-30 13:41:31,078 [Service-0] INFO: Cleaning up ports for service 0\n",
      "2025-09-30 13:41:31,078 [MicroserviceManager] INFO: Port 2000 is in use, cleaning up...\n",
      "2025-09-30 13:41:33,212 [MicroserviceManager] WARNING: Port 2000 still in use after cleanup\n",
      "2025-09-30 13:41:34,214 [Service-0] ERROR: Port 2000 still in use after cleanup\n",
      "2025-09-30 13:41:34,214 [MicroserviceManager] ERROR: Failed to spawn service 0\n",
      "2025-09-30 13:41:34,214 [MicroserviceManager] INFO: Waiting 30s before starting next service...\n"
     ]
    }
   ],
   "source": [
    "import logging, os, signal, subprocess, time, shutil\n",
    "from typing import Set, List  # add this\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def _pids_listening_on_port(port: int, only_mine: bool = True) -> Set[int]:\n",
    "    \"\"\"\n",
    "    Return PIDs listening on `port`. Prefers `lsof`, falls back to `ss` if available.\n",
    "    Only returns LISTEN sockets, not established connections.\n",
    "    \"\"\"\n",
    "    pids = set()\n",
    "\n",
    "    if shutil.which(\"lsof\"):\n",
    "        # -iTCP -sTCP:LISTEN limits to listening TCP sockets\n",
    "        cmd = [\"lsof\", \"-nP\", \"-tiTCP:%d\" % port, \"-sTCP:LISTEN\"]\n",
    "        if only_mine:\n",
    "            cmd.insert(1, \"-u\")\n",
    "            cmd.insert(2, os.getlogin())\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if res.returncode == 0 and res.stdout.strip():\n",
    "            pids.update(int(x) for x in res.stdout.strip().splitlines() if x.strip().isdigit())\n",
    "        return pids\n",
    "\n",
    "    if shutil.which(\"ss\"):\n",
    "        # Linux: parse `ss` output for LISTEN sockets\n",
    "        # Example line: LISTEN 0 128 0.0.0.0:2000 ... users:((\"CarlaUE4\",pid=1234,fd=42))\n",
    "        res = subprocess.run([\"ss\", \"-lptn\"], capture_output=True, text=True)\n",
    "        if res.returncode == 0:\n",
    "            for line in res.stdout.splitlines():\n",
    "                if f\":{port} \" in line or line.endswith(f\":{port}\") or f\":{port},\" in line:\n",
    "                    if \"LISTEN\" not in line:\n",
    "                        continue\n",
    "                    # Pull out pid=NNN tokens\n",
    "                    for tok in line.split():\n",
    "                        if tok.startswith(\"pid=\") and tok[4:].rstrip(\",)\") .isdigit():\n",
    "                            pids.add(int(tok[4:].rstrip(\",)\")))\n",
    "    return pids\n",
    "\n",
    "def _graceful_kill(pids: Set[int], grace: float = 2.5):\n",
    "    \"\"\"Send SIGTERM, wait up to `grace` seconds, then SIGKILL leftovers.\"\"\"\n",
    "    if not pids:\n",
    "        return\n",
    "    me = os.getpid()\n",
    "    pids = {pid for pid in pids if pid != me}\n",
    "    if not pids:\n",
    "        return\n",
    "\n",
    "    for pid in pids:\n",
    "        try:\n",
    "            os.kill(pid, signal.SIGTERM)\n",
    "            logger.info(f\"SIGTERM sent to PID {pid}\")\n",
    "        except ProcessLookupError:\n",
    "            pass\n",
    "        except PermissionError:\n",
    "            logger.warning(f\"Permission denied sending SIGTERM to {pid}\")\n",
    "\n",
    "    deadline = time.time() + grace\n",
    "    remaining = set(pids)\n",
    "    while time.time() < deadline and remaining:\n",
    "        for pid in list(remaining):\n",
    "            try:\n",
    "                os.kill(pid, 0)\n",
    "            except ProcessLookupError:\n",
    "                remaining.discard(pid)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    for pid in list(remaining):\n",
    "        try:\n",
    "            os.kill(pid, signal.SIGKILL)\n",
    "            logger.info(f\"SIGKILL sent to stubborn PID {pid}\")\n",
    "        except ProcessLookupError:\n",
    "            pass\n",
    "        except PermissionError:\n",
    "            logger.warning(f\"Permission denied sending SIGKILL to {pid}\")\n",
    "\n",
    "def clean_ports(ports: List[int], only_mine: bool = True):\n",
    "    \"\"\"Kill processes LISTENing on the given ports.\"\"\"\n",
    "    all_pids = set()\n",
    "    for port in ports:\n",
    "        try:\n",
    "            pids = _pids_listening_on_port(port, only_mine=only_mine)\n",
    "            if pids:\n",
    "                logger.info(f\"Port {port} in use by PIDs {sorted(pids)}\")\n",
    "                all_pids.update(pids)\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error checking port {port}: {e}\")\n",
    "\n",
    "    if all_pids:\n",
    "        _graceful_kill(all_pids)\n",
    "    else:\n",
    "        logger.info(\"No listeners found on target ports.\")\n",
    "\n",
    "def start_servers(num_services: int = 2, root_dir: str = \"/mnt3/Documents/AD_Framework/bench2drive-gymnasium/bench2drive_microservices\"):\n",
    "    logger.info(f\"Starting {num_services} CARLA services...\")\n",
    "\n",
    "    # 0) Clean named processes (gentle first, then escalate)\n",
    "    kill_names = [\"carla_server.py\", \"microservice_manager.py\", \"CarlaUE4\", \"server_manager.py\"]\n",
    "    for name in kill_names:\n",
    "        # Try pkill TERM first\n",
    "        subprocess.run([\"pkill\", \"-f\", name], capture_output=True)\n",
    "        time.sleep(0.2)\n",
    "        # Escalate only if still present\n",
    "        subprocess.run([\"pkill\", \"-9\", \"-f\", name], capture_output=True)\n",
    "\n",
    "    # 1) Clean precise ports (LISTEN only). Adjust lists to your topology.\n",
    "    api_ports = list(range(8080, 8084))          # 8080-8083\n",
    "    carla_ports = list(range(2000, 2013))        # 2000-2012\n",
    "    tm_ports = list(range(3000, 3013))           # 3000-3012\n",
    "    clean_ports(api_ports + carla_ports + tm_ports, only_mine=True)\n",
    "\n",
    "    # 2) Small wait for the OS to release sockets (TIME_WAIT doesn’t apply to LISTEN)\n",
    "    time.sleep(1.0)\n",
    "\n",
    "    # 3) Start microservice manager\n",
    "    cmd = [\n",
    "        \"python\",\n",
    "        os.path.join(root_dir, \"server\", \"microservice_manager.py\"),\n",
    "        \"--num-services\", str(num_services),\n",
    "        \"--startup-delay\", \"30\",\n",
    "    ]\n",
    "    logger.info(f\"Launching: {' '.join(cmd)}\")\n",
    "    subprocess.Popen(cmd)\n",
    "\n",
    "start_servers(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import subprocess\n",
    "# import time\n",
    "# import os\n",
    "\n",
    "# # Setup logging\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "#     datefmt='%Y-%m-%d %H:%M:%S'\n",
    "# )\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# root_dir = \"/mnt3/Documents/AD_Framework/bench2drive-gymnasium/bench2drive_microservices\"\n",
    "# def start_servers(num_services: int = 2):\n",
    "#     \"\"\"Start CARLA servers if needed.\"\"\"\n",
    "#     logger.info(f\"Starting {num_services} CARLA services...\")\n",
    "    \n",
    "#     # Kill existing processes comprehensively\n",
    "#     logger.info(\"Cleaning up existing processes...\")\n",
    "#     processes_to_kill = [\n",
    "#         \"carla_server.py\",\n",
    "#         \"microservice_manager.py\",\n",
    "#         \"CarlaUE4\",\n",
    "#         \"server_manager.py\"\n",
    "#     ]\n",
    "    \n",
    "#     for process in processes_to_kill:\n",
    "#         result = subprocess.run([\"pkill\", \"-f\", process], capture_output=True)\n",
    "#         if result.returncode == 0:\n",
    "#             logger.info(f\"  Killed {process} processes\")\n",
    "    \n",
    "#     # Comprehensive port cleanup - clean all potential ports first\n",
    "#     logger.info(\"Cleaning up ports comprehensively...\")\n",
    "\n",
    "#     # Clean API ports (8080-8083)\n",
    "#     for port in range(8080, 8084):\n",
    "#         try:\n",
    "#             result = subprocess.run([\"lsof\", \"-ti\", f\":{port}\"], capture_output=True, text=True)\n",
    "#             if result.returncode == 0:\n",
    "#                 pids = result.stdout.strip().split('\\n')\n",
    "#                 for pid in pids:\n",
    "#                     if pid:\n",
    "#                         subprocess.run([\"kill\", \"-9\", pid], capture_output=True)\n",
    "#                         logger.info(f\"  Killed process {pid} on port {port}\")\n",
    "#         except Exception as e:\n",
    "#             logger.debug(f\"  Error cleaning port {port}: {e}\")\n",
    "\n",
    "#     # Clean CARLA ports (2000-2012)\n",
    "#     for port in range(2000, 2013):\n",
    "#         try:\n",
    "#             result = subprocess.run([\"lsof\", \"-ti\", f\":{port}\"], capture_output=True, text=True)\n",
    "#             if result.returncode == 0:\n",
    "#                 pids = result.stdout.strip().split('\\n')\n",
    "#                 for pid in pids:\n",
    "#                     if pid:\n",
    "#                         subprocess.run([\"kill\", \"-9\", pid], capture_output=True)\n",
    "#                         logger.info(f\"  Killed process {pid} on port {port}\")\n",
    "#         except Exception as e:\n",
    "#             logger.debug(f\"  Error cleaning port {port}: {e}\")\n",
    "\n",
    "#     # Clean traffic manager ports (3000-3012)\n",
    "#     for port in range(3000, 3013):\n",
    "#         try:\n",
    "#             result = subprocess.run([\"lsof\", \"-ti\", f\":{port}\"], capture_output=True, text=True)\n",
    "#             if result.returncode == 0:\n",
    "#                 pids = result.stdout.strip().split('\\n')\n",
    "#                 for pid in pids:\n",
    "#                     if pid:\n",
    "#                         subprocess.run([\"kill\", \"-9\", pid], capture_output=True)\n",
    "#                         logger.info(f\"  Killed process {pid} on port {port}\")\n",
    "#         except Exception as e:\n",
    "#             logger.debug(f\"  Error cleaning port {port}: {e}\")\n",
    "\n",
    "#     # Wait a moment for ports to be fully released\n",
    "#     time.sleep(2)\n",
    "    \n",
    "#     time.sleep(3)  # Wait for processes to fully terminate\n",
    "    \n",
    "#     # Start microservice manager\n",
    "#     cmd = [\n",
    "#         \"python\",\n",
    "#         os.path.join(root_dir,\"server\",\"microservice_manager.py\"),\n",
    "#         \"--num-services\", str(num_services),\n",
    "#         \"--startup-delay\", \"30\"\n",
    "#     ]\n",
    "    \n",
    "#     proc = subprocess.Popen(cmd)\n",
    "\n",
    "# start_servers(2)\n",
    "# time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Setup\n",
    "\n",
    "⚠️ **IMPORTANT**: For GRPO branching functionality, you need multiple CARLA services running!\n",
    "\n",
    "```bash\n",
    "# Start 2 CARLA microservices for branching\n",
    "python microservice_manager.py --num-services 2\n",
    "```\n",
    "\n",
    "The notebook will automatically detect which ports are available (8080, 8081, 8082, 8083).\n",
    "\n",
    "**Note**: Branching requires at least 2 services to work properly!\n",
    "\n",
    "If you see services running on different ports, that's normal - the notebook will adapt automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully imported GRPOCarlaEnv\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Add client path to Python path\n",
    "client_path = str(Path.cwd().parent / \"client\")\n",
    "if client_path not in sys.path:\n",
    "    sys.path.insert(0, client_path)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Import GRPO Carla environment\n",
    "try:\n",
    "    from grpo_carla_env import GRPOCarlaEnv\n",
    "    print(\"✅ Successfully imported GRPOCarlaEnv\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Setting up GRPO Environment like test script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:42:04,215 [resource_manager] INFO: Allocated resources for service 1:\n",
      "2025-09-30 13:42:04,216 [resource_manager] INFO:   GPU: 1\n",
      "2025-09-30 13:42:04,216 [resource_manager] INFO:   API Port: 8081\n",
      "2025-09-30 13:42:04,216 [resource_manager] INFO:   CARLA Port: 2004\n",
      "2025-09-30 13:42:04,216 [resource_manager] INFO:   Streaming Port: 3010\n",
      "2025-09-30 13:42:04,216 [resource_manager] INFO:   TM Port: 3004\n",
      "2025-09-30 13:42:04,216 [MicroserviceManager] INFO: [Resource Manager] Allocated resources for service 1\n",
      "2025-09-30 13:42:04,217 [Service-1] INFO: Starting service 1\n",
      "2025-09-30 13:42:04,217 [Service-1] INFO: Cleaning up ports for service 1\n",
      "2025-09-30 13:42:05,219 [Service-1] INFO: Starting carla_server.py:\n",
      "2025-09-30 13:42:05,219 [Service-1] INFO:   API port: 8081\n",
      "2025-09-30 13:42:05,219 [Service-1] INFO:   CARLA port: 2004\n",
      "2025-09-30 13:42:05,219 [Service-1] INFO:   GPU: 1\n",
      "2025-09-30 13:42:05,226 [Service-1] INFO: Server process started with PID 271707\n",
      "2025-09-30 13:42:07,239 [Service-1] INFO: Server is healthy\n",
      "2025-09-30 13:42:07,239 [Service-1] INFO: ✓ Service 1 ready\n",
      "2025-09-30 13:42:07,239 [MicroserviceManager] INFO: ✓ Spawned service 1\n",
      "2025-09-30 13:42:07,239 [MicroserviceManager] INFO:   API: http://localhost:8081\n",
      "2025-09-30 13:42:07,239 [MicroserviceManager] INFO:   CARLA port: 2004\n",
      "2025-09-30 13:42:07,239 [MicroserviceManager] INFO:   GPU: 1\n",
      "2025-09-30 13:42:07,240 [MicroserviceManager] INFO: Manager started with 1 services\n",
      "2025-09-30 13:42:07,240 [MicroserviceManager] INFO: Services running. Press Ctrl+C to stop.\n",
      "ERROR:grpo_carla_env:Service at http://localhost:8080 not ready after 30 seconds\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Service http://localhost:8080 not ready",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔧 Setting up GRPO Environment like test script...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Use the same configuration as the working test script\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mGRPOCarlaEnv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_services\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Exactly like test script\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_api_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBASE_API_PORT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Exactly like test script\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb_array\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTIMEOUT\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Pre-initialize all services for fast branching - exactly like test script (line 752)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🌿 Pre-initializing all services for fast branching...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt3/Documents/AD_Framework/bench2drive-gymnasium/bench2drive_microservices/client/grpo_carla_env.py:167\u001b[0m, in \u001b[0;36mGRPOCarlaEnv.__init__\u001b[0;34m(self, num_services, service_urls, base_api_port, render_mode, max_steps, timeout, **env_kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprimary_env_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Index of primary environment in single mode\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Create primary environment\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_env\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Define action/observation spaces from primary env\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39maction_space\n",
      "File \u001b[0;32m/mnt3/Documents/AD_Framework/bench2drive-gymnasium/bench2drive_microservices/client/grpo_carla_env.py:300\u001b[0m, in \u001b[0;36mGRPOCarlaEnv._create_env\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[idx] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# Wait for service to be ready\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_service_ready(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice_urls[idx]):\n\u001b[0;32m--> 300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mService \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice_urls[idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not ready\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[idx] \u001b[38;5;241m=\u001b[39m CarlaEnv(\n\u001b[1;32m    304\u001b[0m             server_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice_urls[idx],\n\u001b[1;32m    305\u001b[0m             render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Handle rendering at wrapper level\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_kwargs\n\u001b[1;32m    309\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Service http://localhost:8080 not ready"
     ]
    }
   ],
   "source": [
    "# Configuration - Follow the working test script approach\n",
    "BASE_API_PORT = 8080  # Start from port 8080 like the test script\n",
    "TIMEOUT = 60.0\n",
    "\n",
    "# Create GRPO environment exactly like the test script\n",
    "print(\"🔧 Setting up GRPO Environment like test script...\")\n",
    "\n",
    "# Use the same configuration as the working test script\n",
    "env = GRPOCarlaEnv(\n",
    "    num_services=2,  # Exactly like test script\n",
    "    base_api_port=BASE_API_PORT,  # Exactly like test script\n",
    "    render_mode=\"rgb_array\",\n",
    "    max_steps=100,\n",
    "    timeout=TIMEOUT\n",
    ")\n",
    "\n",
    "# Pre-initialize all services for fast branching - exactly like test script (line 752)\n",
    "print(\"🌿 Pre-initializing all services for fast branching...\")\n",
    "init_status = env.initialize_all_services(route_id=0)\n",
    "\n",
    "if init_status.ready:\n",
    "    print(\"✓ All services pre-initialized successfully - exactly like test script!\")\n",
    "else:\n",
    "    print(f\"⚠ Service pre-initialization issues: {init_status.message}\")\n",
    "    print(\"   Continuing anyway...\")\n",
    "\n",
    "# Helper function to create actions\n",
    "def create_action(throttle=0.0, brake=0.0, steer=0.0):\n",
    "    \"\"\"Create a valid action vector.\"\"\"\n",
    "    action = np.array([throttle, brake, steer], dtype=np.float32)\n",
    "    return np.clip(action, env.action_space.low, env.action_space.high)\n",
    "\n",
    "print(f\"\\n✅ GRPO Environment created!\")\n",
    "print(f\"📊 Configuration:\")\n",
    "print(f\"   Max branches: {env.max_branches}\")\n",
    "print(f\"   Service URLs: {env.service_urls}\")\n",
    "print(f\"   Current mode: {env.current_mode}\")\n",
    "print(f\"   Is branching: {env.is_branching}\")\n",
    "\n",
    "if len(env.service_urls) < 2:\n",
    "    print(\"\\n⚠️  WARNING: Only 1 service available!\")\n",
    "    print(\"   Make sure both services are running\")\n",
    "else:\n",
    "    print(f\"\\n🎉 Perfect! Both services ready for branching!\")\n",
    "\n",
    "print(\"envs\", env.envs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Exploration in Single Mode\n",
    "\n",
    "First, let's explore the environment to reach an interesting decision point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pre-initialized state for exploration - exactly like test script (lines 475-477)\n",
    "print(\"🚗 Starting initial exploration with pre-initialized state...\")\n",
    "\n",
    "if env.envs[0].last_observation is not None:\n",
    "    # Use pre-initialized state\n",
    "    obs = env.envs[0].last_observation\n",
    "    info = {}\n",
    "    print(f\"Using pre-initialized state. Mode: {env.current_mode}, is_branching: {env.is_branching}\")\n",
    "else:\n",
    "    # Reset environment if not pre-initialized\n",
    "    print(\"Resetting environment for Phase 1...\")\n",
    "    obs, info = env.reset(options={\"route_id\": 0})\n",
    "    print(f\"Reset complete. Mode: {env.current_mode}, is_branching: {env.is_branching}\")\n",
    "\n",
    "trajectory = []\n",
    "total_reward = 0.0\n",
    "\n",
    "# Explore for 20 steps to reach a decision point\n",
    "for step in range(100):\n",
    "    # Vary actions to create an interesting scenario\n",
    "    if step < 10:\n",
    "        # First, move forward\n",
    "        action = create_action(throttle=1.0, brake=0.0, steer=0.0)\n",
    "    else:\n",
    "        # Then add some steering variation\n",
    "        action = create_action(throttle=1.0, brake=0.0, steer=0.3 * np.sin(step * 0.5))\n",
    "    \n",
    "    obs, reward, terminated, truncated, info = env.single_step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    trajectory.append({\n",
    "        'step': step,\n",
    "        'position': obs['vehicle_state']['position'],\n",
    "        'speed': obs['vehicle_state']['speed'][0],\n",
    "        'action': action.tolist(),\n",
    "        'reward': reward,\n",
    "        'image': obs['center_image'].copy()  # Store image for visualization\n",
    "    })\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        print(f\"Step {step:2d}: pos=({obs['vehicle_state']['position'][0]:6.1f}, {obs['vehicle_state']['position'][1]:6.1f}), \"\n",
    "              f\"speed={obs['vehicle_state']['speed'][0]:4.1f} m/s, reward={reward:.3f}\")\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        print(f\"🏁 Episode ended at step {step}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n📊 Exploration completed:\")\n",
    "print(f\"   Total steps: {len(trajectory)}\")\n",
    "print(f\"   Total reward: {total_reward:.3f}\")\n",
    "print(f\"   Final speed: {trajectory[-1]['speed']:.2f} m/s\")\n",
    "\n",
    "# Show final state before snapshot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(trajectory[-1]['image'])\n",
    "plt.title(f\"State Before Snapshot - Step {len(trajectory)-1}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Snapshot System\n",
    "\n",
    "Now let's explore the snapshot functionality - this is the core of GRPO's multi-turn rollout capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current state for branching\n",
    "print(\"💾 Saving snapshot for branching...\")\n",
    "\n",
    "try:\n",
    "    snapshot_id = env.save_snapshot()\n",
    "    print(f\"✅ Snapshot saved successfully!\")\n",
    "    print(f\"   Snapshot ID: {snapshot_id}\")\n",
    "    print(f\"   Saved at step: {env.episode_steps}\")\n",
    "    print(f\"   Current position: {trajectory[-1]['position']}\")\n",
    "    print(f\"   Current speed: {trajectory[-1]['speed']:.2f} m/s\")\n",
    "    print(f\"   Current mode: {env.current_mode}\")\n",
    "    print(f\"   Is branching: {env.is_branching}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to save snapshot: {e}\")\n",
    "    print(\"💡 Make sure you're in single mode before saving snapshot\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate snapshot information\n",
    "print(\"📋 Snapshot System Information\")\n",
    "print(\"=\" * 40)\n",
    "print()\n",
    "print(\"✅ What is a Snapshot?\")\n",
    "print(\"   A snapshot captures the complete state of the CARLA environment:\")\n",
    "print(\"   • Vehicle position and orientation\")\n",
    "print(\"   • Vehicle velocity and speed\")\n",
    "print(\"   • Traffic light states\")\n",
    "print(\"   • Weather and time of day\")\n",
    "print(\"   • Scenario progress and triggers\")\n",
    "print(\"   • Agent internal state\")\n",
    "print()\n",
    "print(\"✅ Why Use Snapshots?\")\n",
    "print(\"   • Multi-turn rollouts: Explore from same state multiple times\")\n",
    "print(\"   • Decision points: Save at critical moments for branching\")\n",
    "print(\"   • Reproducibility: Replay exact scenarios\")\n",
    "print(\"   • GRPO optimization: Compare different action sequences\")\n",
    "print()\n",
    "print(f\"✅ Current Snapshot Status:\")\n",
    "print(f\"   Snapshot ID: {snapshot_id}\")\n",
    "print(f\"   Branch start step: {env.branch_start_step}\")\n",
    "print(f\"   Can branch: {env.current_snapshot is not None}\")\n",
    "print(f\"   Mode: {env.current_mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Simple Branching Demo\n",
    "print(\"\\n🌿 Starting simple branching demonstration...\")\n",
    "\n",
    "try:\n",
    "    # Enable branching with 2 branches\n",
    "    print(\"🌿 Enabling branching mode...\")\n",
    "    status = env.enable_branching(snapshot_id, num_branches=2, async_setup=False)\n",
    "    \n",
    "    if status.status.value == \"branching_ready\":\n",
    "        print(\"✅ Branching enabled successfully!\")\n",
    "        print(f\"   Active branches: {env.active_branches}\")\n",
    "        print(f\"   Mode: {env.current_mode}\")\n",
    "        \n",
    "        # Run 15 steps of branching\n",
    "        print(\"\\n🧪 Running 15 steps with 2 branches...\")\n",
    "        print(\"   Branch 0: Straight driving\")\n",
    "        print(\"   Branch 1: Right turns\")\n",
    "        \n",
    "        total_rewards = [0, 0]\n",
    "        branch_images = []\n",
    "        \n",
    "        for step in range(30):\n",
    "            # Create different actions for each branch\n",
    "            actions = [\n",
    "                np.array([1.0, 0.0, 0.0], dtype=np.float32),   # Branch 0: Straight\n",
    "                np.array([1.0, 0.0, 1.0], dtype=np.float32)    # Branch 1: Right turn\n",
    "            ]\n",
    "            \n",
    "            # Execute branch step\n",
    "            observations, rewards, terminateds, truncateds, infos = env.branch_step(actions)\n",
    "            \n",
    "            # Accumulate rewards\n",
    "            for i in range(2):\n",
    "                total_rewards[i] += rewards[i]\n",
    "            \n",
    "            # Store images for final display\n",
    "            branch_images.append([obs['center_image'].copy() for obs in observations])\n",
    "            \n",
    "            # Show progress every 5 steps\n",
    "            if (step + 1) % 5 == 0:\n",
    "                print(f\"   Step {step + 1}: Branch 0 = {total_rewards[0]:.2f}, Branch 1 = {total_rewards[1]:.2f}\")\n",
    "        \n",
    "        # Show final images from both branches\n",
    "        print(\"\\n📸 Final Branch States:\")\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        for i in range(2):\n",
    "            axes[i].imshow(branch_images[-1][i])\n",
    "            axes[i].set_title(f\"Branch {i} - Final State (Reward: {total_rewards[i]:.3f})\")\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Show results but don't select yet\n",
    "        print(\"\\n🏆 Branching Results:\")\n",
    "        print(f\"   Branch 0 total reward: {total_rewards[0]:.3f}\")\n",
    "        print(f\"   Branch 1 total reward: {total_rewards[1]:.3f}\")\n",
    "        print(\"   Ready for branch selection...\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"❌ Branching failed: {status.message}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Branch Selection\n",
    "print(\"\\n🏆 Selecting best branch...\")\n",
    "\n",
    "import numpy\n",
    "\n",
    "# Select best branch based on rewards\n",
    "best_branch = np.randint(0,2)\n",
    "\n",
    "# Select the branch\n",
    "env.select_branch(best_branch)\n",
    "print(f\"✅ Branch {best_branch} selected - continuing in single mode\")\n",
    "\n",
    "# 7. Continue from Selected Branch - Prove it works for many steps\n",
    "print(f\"\\n🚗 Continuing from Branch {best_branch} for 30 steps to prove selection works...\")\n",
    "\n",
    "# Continue for 30 more steps to prove the selection works\n",
    "continuation_reward = 0\n",
    "for step in range(30):\n",
    "    # Simple forward driving\n",
    "    action = create_action(throttle=1.0, brake=0.0, steer=0.0)\n",
    "    \n",
    "    obs, reward, terminated, truncated, info = env.single_step(action)\n",
    "    continuation_reward += reward\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        pos = obs['vehicle_state']['position']\n",
    "        speed = obs['vehicle_state']['speed'][0]\n",
    "        print(f\"   Step {step}: pos=({pos[0]:.1f}, {pos[1]:.1f}), speed={speed:.1f} m/s\")\n",
    "    \n",
    "    # if terminated or truncated:\n",
    "    #     print(f\"   Episode ended at step {step}\")\n",
    "    #     break\n",
    "\n",
    "print(f\"\\n📊 Continuation completed:\")\n",
    "print(f\"   Total steps: {step + 1}\")\n",
    "print(f\"   Total reward: {continuation_reward:.3f}\")\n",
    "\n",
    "print(f\"\\n✅ PROOF: Successfully continued for {step + 1} steps from selected branch {best_branch}!\")\n",
    "print(f\"   This proves the branch selection and continuation works correctly!\")\n",
    "\n",
    "# Show final state\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(obs['center_image'])\n",
    "plt.title(f\"Final State - Branch {best_branch} Selected (Proof of Continuation)\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Clean up\n",
    "env.close()\n",
    "print(\"\\n✅ Tutorial completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ad_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
